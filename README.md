# ğŸ§¹ Data Cleaning Dashboard

An intelligent Streamlit-based web app for automated and ML-enhanced data cleaning, evaluation, and recommendation. Supports traditional methods, ML-based strategies, and deep learning (Autoencoders), with learning-based recommendations and PDF summaries.

---

## ğŸš€ Features

- ğŸ“‚ Upload and preview CSV files
- ğŸ§¼ Choose from:
  - Traditional Cleaning
  - ML-Based Cleaning
  - Autoencoder Cleaning
  - Auto mode (with recommender)
- ğŸ” Regex-based text column cleaning
- ğŸ§  Cleaning method recommender (trained on logs)
- ğŸ“ˆ Model evaluation (classification & regression)
- ğŸ§® Cleaning score with metrics
- ğŸ§¾ PDF summary export
- ğŸ” Learns from each run to improve recommendations

---

## ğŸ“¦ Requirements

Create a virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install --upgrade pip
pip install -r requirements.txt
If deploying on Streamlit Cloud, make sure .streamlit/config.toml exists:

toml
Copy
Edit
[general]
pythonVersion = "3.11"
ğŸ§ª Running Locally
bash
Copy
Edit
streamlit run full_data_cleaning_dashboard_final.py
ğŸ§  Learning & Recommender
Each cleaning job is logged to learning_log.csv with features like:

Number of rows/columns

Missing % and duplicates

Numeric/categorical ratio

Chosen method and score

A simple Random Forest classifier is trained every 10 runs to improve future cleaning recommendations.

ğŸ“ Folder Structure
bash
Copy
Edit
.
â”œâ”€â”€ full_data_cleaning_dashboard_final.py   # Streamlit app and logic
â”œâ”€â”€ learning_log.csv                        # Cleaning logs
â”œâ”€â”€ recommender.pkl                         # Trained recommendation model
â”œâ”€â”€ requirements.txt                        # Dependencies
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml                         # Python version for Streamlit Cloud
ğŸ§  Tech Stack
Streamlit

Pandas, NumPy, Scikit-learn, Dask

TensorFlow (Autoencoders)

fpdf (for PDF reports)

â˜ï¸ Deploying to Streamlit Cloud
Push your code to GitHub

Go to Streamlit Cloud

Click "New App"

Select your repo (e.g., ngoubimaximillian12/ddata-cleaning-dashboard)

Use full_data_cleaning_dashboard_final.py as the entry point

Ensure your repo has .streamlit/config.toml and correct requirements.txt

ğŸ›‘ Known Limitations
Autoencoder-based cleaning may be slow on large datasets

TensorFlow requires compatible Python (<3.13)

Currently supports CSV input only

ğŸ¤ Contributing
Contributions are welcome! Fork the repo, make your changes, and submit a pull request.

ğŸ“„ License
MIT License Â© 2025 Ngoubi Maximillian

yaml
Copy
Edit

---

Let me know if youâ€™d like this saved into a file and pushed to your GitHub automatically.







